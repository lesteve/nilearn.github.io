
<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Nilearn: Machine learning for NeuroImaging in Python &mdash; Machine learning for NeuroImaging</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1.4.post1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/copybutton.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Machine learning for NeuroImaging" href="#" />
    <link rel="next" title="1. Introduction: nilearn in a nutshell" href="introduction.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">
<script type="text/javascript">
$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var top = 105 + $('.sphinxsidebarwrapper').offset().top - parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0)),
        sections = {},
        i        = 0,
	url	 = document.URL.replace(/#.*$/, ""),
	current_section = 0;

    // Grab positions of our sections 
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();
	// Lock the table of content to a fixed position once we scroll enough
	if(pos > top){
	    //begin to scroll
	    $('.sphinxsidebarwrapper').css("position", "fixed");
	    $('.sphinxsidebarwrapper').css("top", -105);
	}
	else{
	    //lock it back into place
	    $('.sphinxsidebarwrapper').css("position", "relative");
	    $('.sphinxsidebarwrapper').css("top",0);
	}
            
	// Highlight the current section
	$('a.internal').removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').addClass('active');
    });

});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head>
  <body role="document">
<div id="logo-banner">
  <div class="logo">
    <a href="index.html">
      <img src="_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="auto_examples/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="data_analysis/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="building_blocks/haxby_searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="data_analysis/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="building_blocks/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="np-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="introduction.html" title="1. Introduction: nilearn in a nutshell"
             accesskey="N">next</a> |</li>
<li><a href="index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="#">User Guide</a> |&nbsp;</li>
<li><a href="auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>
 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="AUTHORS.html#citing">citing the
                    scikit-learn</a> if you use it.</p></li>
  </ul>

  <h4>Next topic</h4>
  <p class="topless"><a href="introduction.html"
                        title="next chapter">1. Introduction: nilearn in a nutshell</a></p>

<div class="navbar">
</div> <!-- end navbar -->

<script type="text/javascript">$('#searchbox-ml').show(0);</script>
<script type="text/javascript">$('#searchbox-site').show(0);</script>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="user-guide-table-of-contents">
<span id="user-guide"></span><h1>User guide: table of contents<a class="headerlink" href="#user-guide-table-of-contents" title="Permalink to this headline">Â¶</a></h1>
<style type="text/css">
  div.bodywrapper blockquote {
      margin: 0 ;
  }

  div.toctree-wrapper ul {
      margin-top: 0 ;
      margin-bottom: 0 ;
      padding-left: 10px ;
  }

  li.toctree-l1 {
      padding: 0 0 0.5em 0 ;
      list-style-type: none;
      font-size: 150% ;
      font-weight: bold;
      }

  li.toctree-l1 ul {
      padding-left: 40px ;
  }

  li.toctree-l2 {
      font-size: 75% ;
      list-style-type: square;
      font-weight: normal;
      }

  li.toctree-l3 {
      font-size: 85% ;
      list-style-type: circle;
      font-weight: normal;
      }

</style> <SCRIPT>
 //Function to make the index toctree collapsible
 $(function () {
     $('.toctree-l2')
         .click(function(event){
             if (event.target.tagName.toLowerCase() != "a") {
                 if ($(this).children('ul').length > 0) {
                      $(this).attr('data-content',
                          (!$(this).children('ul').is(':hidden')) ? '\u25ba' : '\u25bc');
                     $(this).children('ul').toggle();
                 }
                 return true; //Makes links clickable
             }
         })
         .mousedown(function(event){ return false; }) //Firefox highlighting fix
         .children('ul').hide();
     // Initialize the values
     $('li.toctree-l2:not(:has(ul))').attr('data-content', '-');
     $('li.toctree-l2:has(ul)').attr('data-content', '\u25ba');
     $('li.toctree-l2:has(ul)').css('cursor', 'pointer');

     $('.toctree-l2').hover(
         function () {
             if ($(this).children('ul').length > 0) {
                 $(this).css('background-color', '#D0D0D0').children('ul').css('background-color', '#F0F0F0');
                 $(this).attr('data-content',
                     (!$(this).children('ul').is(':hidden')) ? '\u25bc' : '\u25ba');
             }
             else {
                 $(this).css('background-color', '#F9F9F9');
             }
         },
         function () {
             $(this).css('background-color', 'white').children('ul').css('background-color', 'white');
             if ($(this).children('ul').length > 0) {
                 $(this).attr('data-content',
                     (!$(this).children('ul').is(':hidden')) ? '\u25bc' : '\u25ba');
             }
         }
     );
 });

 </SCRIPT>

<style type="text/css">
  div.bodywrapper blockquote {
      margin: 0 ;
  }

  div.toctree-wrapper ul {
      margin: 0 ;
      padding-left: 0px ;
  }

  li, ul {
      transition-duration: 0.2s;
  }

  li.toctree-l1 {
      padding: 5px 0 0;
      list-style-type: none;
      font-size: 150% ;
      font-family: Arial, sans-serif;
      background-color: #f2f2f2;
      font-weight: normal;
      color: #20435c;
      margin-left: 0;
      margin-bottom: 1.2em;
      font-weight: bold;
      }

  li.toctree-l1 a {
      padding: 0 0 0 10px ;
      color: #314F64 ;
  }

  li.toctree-l2 {
      padding: 0.25em 0 0.25em 0 ;
      list-style-type: none;
      background-color: #FFFFFF;
      font-size: 85% ;
      font-weight: normal;
  }

  li.toctree-l2 ul {
      padding-left: 40px ;
  }


  li.toctree-l2:before {
      content: attr(data-content) ;
      font-size: 85% ;
      color: #777 ;
      display: inline-block;
      width: 10px;
  }

  li.toctree-l3 {
      font-size: 88% ;
      list-style-type: square;
      font-weight: normal;
  }

  li.toctree-l4 {
      font-size: 93% ;
      list-style-type: circle;
      font-weight: normal;
  }

  div.topic li.toctree-l1 {
      font-size: 100% ;
      font-weight: bold;
      background-color: transparent;
      margin-bottom: 0;
      margin-left: 1.5em;
      display:inline;
  }

  div.topic p {
      font-size: 90% ;
      margin: 0.4ex;
  }

  div.topic p.topic-title {
      display:inline;
      font-size: 100% ;
      margin-bottom: 0;
  }

  div.sidebar {
      width: 25ex ;
  }

</style><div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. Introduction: nilearn in a nutshell</a><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#what-is-nilearn-mvpa-decoding-predictive-models-functional-connectivity">1.1. What is nilearn: MVPA, decoding, predictive models, functional connectivity</a><ul>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#why-is-machine-learning-relevant-to-neuroimaging-a-few-examples">1.1.1. Why is machine learning relevant to NeuroImaging? A few examples!</a></li>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#glossary-machine-learning-vocabulary">1.1.2. Glossary: machine learning vocabulary</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#installing-nilearn">1.2. Installing nilearn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#installing-the-scientific-python-environment">1.2.1. Installing the scientific Python environment</a></li>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#id1">1.2.2. Installing nilearn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#testing-your-installation">1.2.2.1. Testing your installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#installing-the-development-version">1.2.2.2. Installing the development version</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#python-for-neuroimaging-a-quick-start">1.3. Python for NeuroImaging, a quick start</a><ul>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#your-first-steps-with-nilearn">1.3.1. Your first steps with nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#scientific-computing-with-python">1.3.2. Scientific computing with Python</a><ul>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#basic-numerics">1.3.2.1. Basic numerics</a></li>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#scikit-learn-machine-learning-in-python">1.3.2.2. Scikit-learn: machine learning in Python</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#finding-help">1.3.3. Finding help</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="decoding/index.html">2. Decoding and MVPA: predicting from brain images</a><ul>
<li class="toctree-l2"><a class="reference internal" href="decoding/decoding_tutorial.html">2.1. A decoding tutorial</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_tutorial.html#data-loading-and-preparation">2.1.1. Data loading and preparation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_tutorial.html#the-haxby-2001-experiment">2.1.1.1. The Haxby 2001 experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_tutorial.html#loading-the-data-into-python">2.1.1.2. Loading the data into Python</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_tutorial.html#performing-the-decoding-analysis">2.1.2. Performing the decoding analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_tutorial.html#the-prediction-engine">2.1.2.1. The prediction engine</a><ul>
<li class="toctree-l5"><a class="reference internal" href="decoding/decoding_tutorial.html#an-estimator-object">2.1.2.1.1. An estimator object</a></li>
<li class="toctree-l5"><a class="reference internal" href="decoding/decoding_tutorial.html#applying-it-to-data-fit-train-and-predict-test">2.1.2.1.2. Applying it to data: fit (train) and predict (test)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_tutorial.html#measuring-prediction-performance">2.1.2.2. Measuring prediction performance</a><ul>
<li class="toctree-l5"><a class="reference internal" href="decoding/decoding_tutorial.html#cross-validation">2.1.2.2.1. Cross-validation</a></li>
<li class="toctree-l5"><a class="reference internal" href="decoding/decoding_tutorial.html#choosing-a-good-cross-validation-strategy">2.1.2.2.2. Choosing a good cross-validation strategy</a></li>
<li class="toctree-l5"><a class="reference internal" href="decoding/decoding_tutorial.html#choice-of-the-prediction-accuracy-measure">2.1.2.2.3. Choice of the prediction accuracy measure</a></li>
<li class="toctree-l5"><a class="reference internal" href="decoding/decoding_tutorial.html#measuring-the-chance-level">2.1.2.2.4. Measuring the chance level</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_tutorial.html#visualizing-the-decoder-s-weights">2.1.2.3. Visualizing the decoder&#8217;s weights</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_tutorial.html#decoding-without-a-mask-anova-svm">2.1.3. Decoding without a mask: Anova-SVM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_tutorial.html#dimension-reduction-with-feature-selection">2.1.3.1. Dimension reduction with feature selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_tutorial.html#visualizing-the-results">2.1.3.2. Visualizing the results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_tutorial.html#going-further-with-scikit-learn">2.1.4. Going further with scikit-learn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_tutorial.html#changing-the-prediction-engine">2.1.4.1. Changing the prediction engine</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_tutorial.html#changing-the-feature-selection">2.1.4.2. Changing the feature selection</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decoding/estimator_choice.html">2.2. Choosing the right predictive model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/estimator_choice.html#predictions-regression-classification-and-multi-class">2.2.1. Predictions: regression, classification and multi-class</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/estimator_choice.html#regression">2.2.1.1. Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/estimator_choice.html#classification-two-classes-or-multi-class">2.2.1.2. Classification: two classes or multi-class</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/estimator_choice.html#setting-estimator-parameters">2.2.2. Setting estimator parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/estimator_choice.html#different-linear-models">2.2.3. Different linear models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decoding/decoding_simulated.html">2.3. Decoding on simulated data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_simulated.html#simple-neuroimaging-like-simulations">2.3.1. Simple NeuroImaging-like simulations</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_simulated.html#running-various-estimators">2.3.2. Running various estimators</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decoding/searchlight.html">2.4. Searchlight : finding voxels containing information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html#principle-of-the-searchlight">2.4.1. Principle of the Searchlight</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html#preparing-the-data">2.4.2. Preparing the data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#loading">2.4.2.1. Loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#reshaping-the-data">2.4.2.2. Reshaping the data</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#masking">2.4.2.3. Masking</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html#third-step-setting-up-the-searchlight">2.4.3. Third Step: Setting up the searchlight</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#classifier">2.4.3.1. Classifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#score-function">2.4.3.2. Score function</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#cross-validation">2.4.3.3. Cross validation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html#running-searchlight">2.4.4. Running Searchlight</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html#visualization">2.4.5. Visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#id1">2.4.5.1. Searchlight</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#comparing-to-massively-univariate-analysis-f-score-or-spm">2.4.5.2. Comparing to massively univariate analysis: F_score or SPM</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="connectivity/index.html">3. Functional connectivity and resting state</a><ul>
<li class="toctree-l2"><a class="reference internal" href="connectivity/functional_connectomes.html">3.1. Extracting times series to build a functional connectome</a><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/functional_connectomes.html#time-series-from-a-brain-parcellation-or-maxprob-atlas">3.1.1. Time-series from a brain parcellation or &#8220;MaxProb&#8221; atlas</a><ul>
<li class="toctree-l4"><a class="reference internal" href="connectivity/functional_connectomes.html#brain-parcellations">3.1.1.1. Brain parcellations</a></li>
<li class="toctree-l4"><a class="reference internal" href="connectivity/functional_connectomes.html#extracting-signals-on-a-parcellation">3.1.1.2. Extracting signals on a parcellation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/functional_connectomes.html#time-series-from-a-probabilistic-atlas">3.1.2. Time-series from a probabilistic atlas</a><ul>
<li class="toctree-l4"><a class="reference internal" href="connectivity/functional_connectomes.html#probabilistic-atlases">3.1.2.1. Probabilistic atlases</a></li>
<li class="toctree-l4"><a class="reference internal" href="connectivity/functional_connectomes.html#extracting-signals-from-a-probabilistic-atlas">3.1.2.2. Extracting signals from a probabilistic atlas</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/functional_connectomes.html#a-functional-connectome-a-graph-of-interactions">3.1.3. A functional connectome: a graph of interactions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="connectivity/connectome_extraction.html">3.2. Connectome extraction: inverse covariance for direct connections</a><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/connectome_extraction.html#sparse-inverse-covariance-for-functional-connectomes">3.2.1. Sparse inverse covariance for functional connectomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/connectome_extraction.html#sparse-inverse-covariance-on-multiple-subjects">3.2.2. Sparse inverse covariance on multiple subjects</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/connectome_extraction.html#comparing-the-different-approaches-on-simulated-data">3.2.3. Comparing the different approaches on simulated data</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="connectivity/resting_state_networks.html">3.3. Extracting resting-state networks with ICA</a><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/resting_state_networks.html#data-preparation-retrieving-example-data">3.3.1. Data preparation: retrieving example data</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/resting_state_networks.html#applying-canica">3.3.2. Applying CanICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/resting_state_networks.html#visualizing-the-results">3.3.3. Visualizing the results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="connectivity/parcellating.html">3.4. Parcellating the brain in regions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/parcellating.html#a-resting-state-dataset">3.4.1. A resting-state dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/parcellating.html#preprocessing-loading-and-masking">3.4.2. Preprocessing: loading and masking</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/parcellating.html#applying-ward-clustering">3.4.3. Applying Ward clustering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="connectivity/parcellating.html#running-the-ward-algorithm">3.4.3.1. Running the Ward algorithm</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/parcellating.html#post-processing-and-visualizing-the-parcels">3.4.4. Post-Processing and visualizing the parcels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="connectivity/parcellating.html#unmasking">3.4.4.1. Unmasking</a></li>
<li class="toctree-l4"><a class="reference internal" href="connectivity/parcellating.html#label-visualization">3.4.4.2. Label visualization</a></li>
<li class="toctree-l4"><a class="reference internal" href="connectivity/parcellating.html#compressed-picture">3.4.4.3. Compressed picture</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="manipulating_visualizing/index.html">4. Image manipulation and visualization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="manipulating_visualizing/plotting.html">4.1. Plotting brain images</a><ul>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/plotting.html#different-plotting-functions">4.1.1. Different plotting functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/plotting.html#different-display-modes">4.1.2. Different display modes</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/plotting.html#adding-overlays-edges-and-contours">4.1.3. Adding overlays, edges and contours</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/plotting.html#saving-to-an-image-file">4.1.4. Saving to an image file</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="manipulating_visualizing/data_preparation.html">4.2. Data preparation: loading and basic transformation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#the-concept-of-masker-objects">4.2.1. The concept of &#8220;masker&#8221; objects</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#niftimasker-loading-masking-and-filtering">4.2.2. <code class="docutils literal"><span class="pre">NiftiMasker</span></code>: loading, masking and filtering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#custom-data-loading">4.2.2.1. Custom data loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#controlling-how-the-mask-is-computed-from-the-data">4.2.2.2. Controlling how the mask is computed from the data</a><ul>
<li class="toctree-l5"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#computing-the-mask">4.2.2.2.1. Computing the mask</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#common-data-preparation-steps-resampling-smoothing-filtering">4.2.2.3. Common data preparation steps: resampling, smoothing, filtering</a><ul>
<li class="toctree-l5"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#resampling">4.2.2.3.1. Resampling</a></li>
<li class="toctree-l5"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#smoothing">4.2.2.3.2. Smoothing</a></li>
<li class="toctree-l5"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#temporal-filtering">4.2.2.3.3. Temporal Filtering</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#inverse-transform-unmasking-data">4.2.2.4. Inverse transform: unmasking data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#extraction-of-signals-from-regions-niftilabelsmasker-niftimapsmasker">4.2.3. Extraction of signals from regions: <code class="docutils literal"><span class="pre">NiftiLabelsMasker</span></code>, <code class="docutils literal"><span class="pre">NiftiMapsMasker</span></code>.</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#regions-definition">4.2.3.1. Regions definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#niftimapsmasker-usage">4.2.3.2. <code class="docutils literal"><span class="pre">NiftiMapsMasker</span></code> Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/data_preparation.html#niftilabelsmasker-usage">4.2.3.3. <code class="docutils literal"><span class="pre">NiftiLabelsMasker</span></code> Usage</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html">4.3. Manipulating brain volume: input/output, masking, ROIs, smoothing...</a><ul>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#loading-data">4.3.1. Loading data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#fetching-datasets">4.3.1.1. Fetching datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#loading-your-own-data">4.3.1.2. Loading your own data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#understanding-neuroimaging-data">4.3.2. Understanding Neuroimaging data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#nifti-and-analyze-files">4.3.2.1. Nifti and Analyze files</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#niimg-like-objects">4.3.2.2. Niimg-like objects</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#text-files-phenotype-or-behavior">4.3.2.3. Text files: phenotype or behavior</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#masking-data-manually">4.3.3. Masking data manually</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#extracting-a-brain-mask">4.3.3.1. Extracting a brain mask</a><ul>
<li class="toctree-l5"><a class="reference internal" href="manipulating_visualizing/generated/nilearn.masking.compute_epi_mask.html">4.3.3.1.1. nilearn.masking.compute_epi_mask</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#from-4d-to-2d-arrays">4.3.3.2. From 4D to 2D arrays</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#functions-for-data-preparation-steps">4.3.4. Functions for data preparation steps</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#image-operations-creating-a-roi-mask-manually">4.3.5. Image operations: creating a ROI mask manually</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#smoothing">4.3.5.1. Smoothing</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#selecting-features">4.3.5.2. Selecting features</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#thresholding">4.3.5.3. Thresholding</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#mask-intersection">4.3.5.4. Mask intersection</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#mask-dilation">4.3.5.5. Mask dilation</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#extracting-connected-components">4.3.5.6. Extracting connected components</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_visualizing/manipulating_images.html#saving-the-result">4.3.5.7. Saving the result</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="building_blocks/index.html">5. Advanced usage: manual pipelines and scaling up</a><ul>
<li class="toctree-l2"><a class="reference internal" href="building_blocks/manual_pipeline.html">5.1. Building your own neuroimaging machine-learning pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html#data-loading-and-preprocessing">5.1.1. Data loading and preprocessing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manual_pipeline.html#downloading-the-data">5.1.1.1. Downloading the data</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manual_pipeline.html#loading-non-image-data-experiment-description">5.1.1.2. Loading non image data: experiment description</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manual_pipeline.html#masking-the-data-from-4d-image-to-2d-array">5.1.1.3. Masking the data: from 4D image to 2D array</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/manual_pipeline.html#applying-a-mask">5.1.1.3.1. Applying a mask</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/manual_pipeline.html#automatically-computing-a-mask">5.1.1.3.2. Automatically computing a mask</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html#applying-a-scikit-learn-machine-learning-method">5.1.2. Applying a scikit-learn machine learning method</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html#unmasking-inverse-transform">5.1.3. Unmasking (inverse_transform)</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html#visualizing-results">5.1.4. Visualizing results</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html#going-further">5.1.5. Going further</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modules/reference.html">6. Reference documentation: all nilearn functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.datasets">6.1. <code class="docutils literal"><span class="pre">nilearn.datasets</span></code>: Automatic Dataset Fetching</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_abide_pcp.html">6.1.1. nilearn.datasets.fetch_abide_pcp</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_adhd.html">6.1.2. nilearn.datasets.fetch_adhd</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_haxby.html">6.1.3. nilearn.datasets.fetch_haxby</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_haxby_simple.html">6.1.4. nilearn.datasets.fetch_haxby_simple</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_icbm152_2009.html">6.1.5. nilearn.datasets.fetch_icbm152_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_localizer_contrasts.html">6.1.6. nilearn.datasets.fetch_localizer_contrasts</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_localizer_calculation_task.html">6.1.7. nilearn.datasets.fetch_localizer_calculation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_miyawaki2008.html">6.1.8. nilearn.datasets.fetch_miyawaki2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_nyu_rest.html">6.1.9. nilearn.datasets.fetch_nyu_rest</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_oasis_vbm.html">6.1.10. nilearn.datasets.fetch_oasis_vbm</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.decoding">6.2. <code class="docutils literal"><span class="pre">nilearn.decoding</span></code>: Decoding</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.decomposition">6.3. <code class="docutils literal"><span class="pre">nilearn.decompositon</span></code>: Multivariate decompositions</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.image">6.4. <code class="docutils literal"><span class="pre">nilearn.image</span></code>: Image processing and resampling utilities</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.input_data">6.5. <code class="docutils literal"><span class="pre">nilearn.input_data</span></code>: Loading and Processing files easily</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.masking">6.6. <code class="docutils literal"><span class="pre">nilearn.masking</span></code>: Data Masking Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.compute_epi_mask.html">6.6.1. nilearn.masking.compute_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.compute_multi_epi_mask.html">6.6.2. nilearn.masking.compute_multi_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.compute_background_mask.html">6.6.3. nilearn.masking.compute_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.compute_multi_background_mask.html">6.6.4. nilearn.masking.compute_multi_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.apply_mask.html">6.6.5. nilearn.masking.apply_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.unmask.html">6.6.6. nilearn.masking.unmask</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.region">6.7. <code class="docutils literal"><span class="pre">nilearn.region</span></code>: Operating on regions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.region.img_to_signals_labels.html">6.7.1. nilearn.region.img_to_signals_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.region.signals_to_img_labels.html">6.7.2. nilearn.region.signals_to_img_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.region.img_to_signals_maps.html">6.7.3. nilearn.region.img_to_signals_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.region.signals_to_img_maps.html">6.7.4. nilearn.region.signals_to_img_maps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.mass_univariate">6.8. <code class="docutils literal"><span class="pre">nilearn.mass_univariate</span></code>: Mass-univariate analysis</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.plotting">6.9. <code class="docutils literal"><span class="pre">nilearn.plotting</span></code>: Plotting brain data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.OrthoSlicer.html">6.9.1. nilearn.plotting.displays.OrthoSlicer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.signal">6.10. <code class="docutils literal"><span class="pre">nilearn.signal</span></code>: Preprocessing Time Series</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.signal.clean.html">6.10.1. nilearn.signal.clean</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="np-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="introduction.html" title="1. Introduction: nilearn in a nutshell"
             >next</a> |</li>
<li><a href="index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="#">User Guide</a> |&nbsp;</li>
<li><a href="auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>
 
      </ul>
    </div>
    <div class="footer">
            &copy; The nilearn developers 2010-2015.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.1.
        <span style="padding-left: 5ex;">
          <a href="_sources/user_guide.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>