
<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Nilearn: Machine learning for NeuroImaging in Python &mdash; Machine learning for NeuroImaging</title>
    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.1.4.post1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="top" title="Machine learning for NeuroImaging" href="../user_guide.html" />
    <link rel="up" title="2. Decoding and MVPA: predicting from brain images" href="index.html" />
    <link rel="next" title="2.2. Choosing the right predictive model" href="estimator_choice.html" />
    <link rel="prev" title="2. Decoding and MVPA: predicting from brain images" href="index.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">
<script type="text/javascript">
$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var top = 105 + $('.sphinxsidebarwrapper').offset().top - parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0)),
        sections = {},
        i        = 0,
	url	 = document.URL.replace(/#.*$/, ""),
	current_section = 0;

    // Grab positions of our sections 
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();
	// Lock the table of content to a fixed position once we scroll enough
	if(pos > top){
	    //begin to scroll
	    $('.sphinxsidebarwrapper').css("position", "fixed");
	    $('.sphinxsidebarwrapper').css("top", -105);
	}
	else{
	    //lock it back into place
	    $('.sphinxsidebarwrapper').css("position", "relative");
	    $('.sphinxsidebarwrapper').css("top",0);
	}
            
	// Highlight the current section
	$('a.internal').removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').addClass('active');
    });

});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head>
  <body role="document">
<div id="logo-banner">
  <div class="logo">
    <a href="../index.html">
      <img src="../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../auto_examples/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../data_analysis/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../building_blocks/haxby_searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../data_analysis/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../building_blocks/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../np-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="estimator_choice.html" title="2.2. Choosing the right predictive model"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="2. Decoding and MVPA: predicting from brain images"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">2. Decoding and MVPA: predicting from brain images</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../AUTHORS.html#citing">citing the
                    scikit-learn</a> if you use it.</p></li>
  </ul>

  <h3><a href="../user_guide.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">2.1. A decoding tutorial</a><ul>
<li><a class="reference internal" href="#data-loading-and-preparation">2.1.1. Data loading and preparation</a><ul>
<li><a class="reference internal" href="#the-haxby-2001-experiment">2.1.1.1. The Haxby 2001 experiment</a></li>
<li><a class="reference internal" href="#loading-the-data-into-python">2.1.1.2. Loading the data into Python</a></li>
</ul>
</li>
<li><a class="reference internal" href="#performing-the-decoding-analysis">2.1.2. Performing the decoding analysis</a><ul>
<li><a class="reference internal" href="#the-prediction-engine">2.1.2.1. The prediction engine</a><ul>
<li><a class="reference internal" href="#an-estimator-object">2.1.2.1.1. An estimator object</a></li>
<li><a class="reference internal" href="#applying-it-to-data-fit-train-and-predict-test">2.1.2.1.2. Applying it to data: fit (train) and predict (test)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#measuring-prediction-performance">2.1.2.2. Measuring prediction performance</a><ul>
<li><a class="reference internal" href="#cross-validation">2.1.2.2.1. Cross-validation</a></li>
<li><a class="reference internal" href="#choosing-a-good-cross-validation-strategy">2.1.2.2.2. Choosing a good cross-validation strategy</a></li>
<li><a class="reference internal" href="#choice-of-the-prediction-accuracy-measure">2.1.2.2.3. Choice of the prediction accuracy measure</a></li>
<li><a class="reference internal" href="#measuring-the-chance-level">2.1.2.2.4. Measuring the chance level</a></li>
</ul>
</li>
<li><a class="reference internal" href="#visualizing-the-decoder-s-weights">2.1.2.3. Visualizing the decoder&#8217;s weights</a></li>
</ul>
</li>
<li><a class="reference internal" href="#decoding-without-a-mask-anova-svm">2.1.3. Decoding without a mask: Anova-SVM</a><ul>
<li><a class="reference internal" href="#dimension-reduction-with-feature-selection">2.1.3.1. Dimension reduction with feature selection</a></li>
<li><a class="reference internal" href="#visualizing-the-results">2.1.3.2. Visualizing the results</a></li>
</ul>
</li>
<li><a class="reference internal" href="#going-further-with-scikit-learn">2.1.4. Going further with scikit-learn</a><ul>
<li><a class="reference internal" href="#changing-the-prediction-engine">2.1.4.1. Changing the prediction engine</a></li>
<li><a class="reference internal" href="#changing-the-feature-selection">2.1.4.2. Changing the feature selection</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">2. Decoding and MVPA: predicting from brain images</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="estimator_choice.html"
                        title="next chapter">2.2. Choosing the right predictive model</a></p>

<div class="navbar">
</div> <!-- end navbar -->

<script type="text/javascript">$('#searchbox-ml').show(0);</script>
<script type="text/javascript">$('#searchbox-site').show(0);</script>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="a-decoding-tutorial">
<span id="decoding-tutorial"></span><h1>2.1. A decoding tutorial<a class="headerlink" href="#a-decoding-tutorial" title="Permalink to this headline">¶</a></h1>
<p>This page is a decoding tutorial articulated on the analysis of the Haxby
2001 dataset. It shows how to predict from brain activity images the
stimuli that the subject is viewing.</p>
<div class="contents local topic" id="contents">
<p class="topic-title first"><strong>Contents</strong></p>
<ul class="simple">
<li><a class="reference internal" href="#data-loading-and-preparation" id="id6">Data loading and preparation</a></li>
<li><a class="reference internal" href="#performing-the-decoding-analysis" id="id7">Performing the decoding analysis</a></li>
<li><a class="reference internal" href="#decoding-without-a-mask-anova-svm" id="id8">Decoding without a mask: Anova-SVM</a></li>
<li><a class="reference internal" href="#going-further-with-scikit-learn" id="id9">Going further with scikit-learn</a></li>
</ul>
</div>
<div class="section" id="data-loading-and-preparation">
<h2><a class="toc-backref" href="#id6">2.1.1. Data loading and preparation</a><a class="headerlink" href="#data-loading-and-preparation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-haxby-2001-experiment">
<h3>2.1.1.1. The Haxby 2001 experiment<a class="headerlink" href="#the-haxby-2001-experiment" title="Permalink to this headline">¶</a></h3>
<p>Subjects are presented visual stimuli from different categories. We are
going to predict which category the subject is seeing from the fMRI
activity recorded in masks of the ventral stream. Significant prediction
shows that the signal in the region contains information on the
corresponding category.</p>
<div class="figure align-left" id="id1">
<a class="reference external image-reference" href="../auto_examples/decoding/plot_haxby_stimuli.html"><img alt="../_images/plot_haxby_stimuli_0041.png" src="../_images/plot_haxby_stimuli_0041.png" style="width: 240.0px; height: 180.0px;" /></a>
<p class="caption"><span class="caption-text">Face stimuli</span></p>
</div>
<div class="figure align-left" id="id2">
<a class="reference external image-reference" href="../auto_examples/decoding/plot_haxby_stimuli.html"><img alt="../_images/plot_haxby_stimuli_0021.png" src="../_images/plot_haxby_stimuli_0021.png" style="width: 240.0px; height: 180.0px;" /></a>
<p class="caption"><span class="caption-text">Cat stimuli</span></p>
</div>
<div class="figure align-left" id="id3">
<a class="reference external image-reference" href="../auto_examples/manipulating_visualizing/plot_haxby_masks.html"><img alt="../_images/plot_haxby_masks_0011.png" src="../_images/plot_haxby_masks_0011.png" style="width: 120.0px; height: 162.0px;" /></a>
<p class="caption"><span class="caption-text">Masks</span></p>
</div>
<div class="figure align-left" id="id4">
<a class="reference external image-reference" href="../auto_examples/decoding/plot_haxby_full_analysis.html"><img alt="../_images/plot_haxby_full_analysis_0011.png" src="../_images/plot_haxby_full_analysis_0011.png" style="width: 280.0px; height: 210.0px;" /></a>
<p class="caption"><span class="caption-text">Decoding scores per mask</span></p>
</div>
</div>
<div class="section" id="loading-the-data-into-python">
<h3>2.1.1.2. Loading the data into Python<a class="headerlink" href="#loading-the-data-into-python" title="Permalink to this headline">¶</a></h3>
<p>Launch IPython:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ipython</span> <span class="o">--</span><span class="n">matplotlib</span>
</pre></div>
</div>
<p>First, load the data using nilearn data downloading function,
<a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_haxby.html#nilearn.datasets.fetch_haxby" title="nilearn.datasets.fetch_haxby"><code class="xref py py-func docutils literal"><span class="pre">nilearn.datasets.fetch_haxby</span></code></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="n">haxby_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_haxby</span><span class="p">()</span>

<span class="c"># print basic information on the dataset</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;First subject anatomical nifti image (3D) is at: </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span>
      <span class="n">haxby_dataset</span><span class="o">.</span><span class="n">anat</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;First subject functional nifti images (4D) are at: </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span>
      <span class="n">haxby_dataset</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c"># 4D data</span>
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">haxby_dataset</span></code> object has several entries that contain paths to the files
downloaded on the disk:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">haxby_dataset</span><span class="p">)</span>  
<span class="go">{&#39;anat&#39;: [&#39;/home/varoquau/dev/nilearn/nilearn_data/haxby2001/subj1/anat.nii.gz&#39;],</span>
<span class="go">&#39;func&#39;: [&#39;/home/varoquau/dev/nilearn/nilearn_data/haxby2001/subj1/bold.nii.gz&#39;],</span>
<span class="go">&#39;mask_face&#39;: [&#39;/home/varoquau/dev/nilearn/nilearn_data/haxby2001/subj1/mask8b_face_vt.nii.gz&#39;],</span>
<span class="go">&#39;mask_face_little&#39;: [&#39;/home/varoquau/dev/nilearn/nilearn_data/haxby2001/subj1/mask8_face_vt.nii.gz&#39;],</span>
<span class="go">&#39;mask_house&#39;: [&#39;/home/varoquau/dev/nilearn/nilearn_data/haxby2001/subj1/mask8b_house_vt.nii.gz&#39;],</span>
<span class="go">&#39;mask_house_little&#39;: [&#39;/home/varoquau/dev/nilearn/nilearn_data/haxby2001/subj1/mask8_house_vt.nii.gz&#39;],</span>
<span class="go">&#39;mask_vt&#39;: [&#39;/home/varoquau/dev/nilearn/nilearn_data/haxby2001/subj1/mask4_vt.nii.gz&#39;],</span>
<span class="go">&#39;session_target&#39;: [&#39;/home/varoquau/dev/nilearn/nilearn_data/haxby2001/subj1/labels.txt&#39;]}</span>
</pre></div>
</div>
<p>We load the behavioral labels from the corresponding text file and limit
our analysis to the <cite>face</cite> and <cite>cat</cite> conditions:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="c"># Load target information as string and give a numerical identifier to each</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">recfromcsv</span><span class="p">(</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">session_target</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">&quot; &quot;</span><span class="p">)</span>

<span class="c"># scikit-learn &gt;= 0.14 supports text labels. You can replace this line by:</span>
<span class="c"># target = labels[&#39;labels&#39;]</span>
<span class="n">_</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="s">&#39;labels&#39;</span><span class="p">],</span> <span class="n">return_inverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c">### Keep only data corresponding to faces or cats #############################</span>
<span class="n">condition_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="s">&#39;labels&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">b</span><span class="s">&#39;face&#39;</span><span class="p">,</span>
                               <span class="n">labels</span><span class="p">[</span><span class="s">&#39;labels&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">b</span><span class="s">&#39;cat&#39;</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="n">condition_mask</span><span class="p">]</span>
</pre></div>
</div>
<p>Then we prepare the fMRI data: we use the <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal"><span class="pre">NiftiMasker</span></code></a> to apply the
<cite>mask_vt</cite> mask to the 4D fMRI data, so that its shape becomes (n_samples,
n_features) (see <a class="reference internal" href="../manipulating_visualizing/manipulating_images.html#mask-4d-2-3d"><span>From 4D to 2D arrays</span></a> for a discussion on using masks).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">seemingly minor data preparation can matter a lot on the final score,
for instance standardizing the data.</p>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn.input_data</span> <span class="kn">import</span> <span class="n">NiftiMasker</span>
<span class="n">mask_filename</span> <span class="o">=</span> <span class="n">haxby_dataset</span><span class="o">.</span><span class="n">mask_vt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c"># For decoding, standardizing is often very important</span>
<span class="n">nifti_masker</span> <span class="o">=</span> <span class="n">NiftiMasker</span><span class="p">(</span><span class="n">mask_img</span><span class="o">=</span><span class="n">mask_filename</span><span class="p">,</span> <span class="n">standardize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">func_filename</span> <span class="o">=</span> <span class="n">haxby_dataset</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c"># We give the nifti_masker a filename and retrieve a 2D array ready</span>
<span class="c"># for machine learning with scikit-learn</span>
<span class="n">fmri_masked</span> <span class="o">=</span> <span class="n">nifti_masker</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">func_filename</span><span class="p">)</span>

<span class="c"># Restrict the classification to the face vs cat discrimination</span>
<span class="n">fmri_masked</span> <span class="o">=</span> <span class="n">fmri_masked</span><span class="p">[</span><span class="n">condition_mask</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<ul class="last simple">
<li><a class="reference internal" href="../manipulating_visualizing/manipulating_images.html#loading-data"><span>Loading data</span></a></li>
<li><a class="reference internal" href="../building_blocks/manual_pipeline.html#masking"><span>Masking the data: from 4D image to 2D array</span></a></li>
</ul>
</div>
</div>
</div>
<div class="section" id="performing-the-decoding-analysis">
<h2><a class="toc-backref" href="#id7">2.1.2. Performing the decoding analysis</a><a class="headerlink" href="#performing-the-decoding-analysis" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-prediction-engine">
<h3>2.1.2.1. The prediction engine<a class="headerlink" href="#the-prediction-engine" title="Permalink to this headline">¶</a></h3>
<div class="section" id="an-estimator-object">
<h4>2.1.2.1.1. An estimator object<a class="headerlink" href="#an-estimator-object" title="Permalink to this headline">¶</a></h4>
<p>To perform decoding we construct an estimator, predicting a condition
label <strong>y</strong> given a set <strong>X</strong> of images.</p>
<p>We use here a simple <a class="reference external" href="http://scikit-learn.org/stable/modules/svm.html">Support Vector Classification</a> (or SVC) with a
linear kernel. We first import the correct module from scikit-learn and we
define the classifier, <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="(in scikit-learn v0.16.dev0)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.svm.SVC</span></code></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">&#39;linear&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The documentation of the object details all parameters. In IPython, it
can be displayed as follows:</p>
<div class="highlight-python"><div class="highlight"><pre>In [10]: svc?
Type:             SVC
Base Class:       &lt;class &#39;sklearn.svm.libsvm.SVC&#39;&gt;
String Form:
SVC(kernel=linear, C=1.0, probability=False, degree=3, coef0=0.0, eps=0.001,
cache_size=100.0, shrinking=True, gamma=0.0)
Namespace:        Interactive
Docstring:
    C-Support Vector Classification.
    Parameters
    ----------
    C : float, optional (default=1.0)
        penalty parameter C of the error term.
...
</pre></div>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last">the <a class="reference external" href="http://scikit-learn.org/stable/modules/svm.html">scikit-learn documentation on SVMs</a></p>
</div>
</div>
<div class="section" id="applying-it-to-data-fit-train-and-predict-test">
<h4>2.1.2.1.2. Applying it to data: fit (train) and predict (test)<a class="headerlink" href="#applying-it-to-data-fit-train-and-predict-test" title="Permalink to this headline">¶</a></h4>
<p>In scikit-learn, the prediction objects have two important methods:</p>
<ul class="simple">
<li>a <em>fit</em> function that &#8220;learns&#8221; the parameters of the model from the data.
Thus, we need to give some training data to <em>fit</em>.</li>
<li>a <em>predict</em> function that &#8220;predicts&#8221; a target from new data.
Here, we just have to give the new set of images (as the target should be
unknown):</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">fmri_masked</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">fmri_masked</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last"><strong>Do not predict on data used by the fit:</strong> the prediction that we obtain here
is to good to be true (see next paragraph). Here we are just doing a sanity
check.</p>
</div>
</div>
</div>
<div class="section" id="measuring-prediction-performance">
<h3>2.1.2.2. Measuring prediction performance<a class="headerlink" href="#measuring-prediction-performance" title="Permalink to this headline">¶</a></h3>
<div class="section" id="cross-validation">
<h4>2.1.2.2.1. Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">¶</a></h4>
<p>However, the last analysis is <em>wrong</em>, as we have learned and tested on
the same set of data. We need to use a cross-validation to split the data
into different sets, called &#8220;folds&#8221;, in a <a class="reference external" href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation">K-Fold strategy</a>.</p>
<p>We use a cross-validation object,
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html#sklearn.cross_validation.KFold" title="(in scikit-learn v0.16.dev0)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.cross_validation.KFold</span></code></a>, that simply generates the
indices of the folds within a loop.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">fmri_masked</span><span class="p">),</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="p">:</span>
    <span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">fmri_masked</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">target</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">fmri_masked</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>
    <span class="n">cv_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">prediction</span> <span class="o">==</span> <span class="n">target</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>
                     <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">target</span><span class="p">[</span><span class="n">test</span><span class="p">])))</span>

<span class="k">print</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
</pre></div>
</div>
<p>There is a specific function,
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score" title="(in scikit-learn v0.16.dev0)"><code class="xref py py-func docutils literal"><span class="pre">sklearn.cross_validation.cross_val_score</span></code></a> that computes for you
the score for the different folds of cross-validation:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">fmri_masked</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
</pre></div>
</div>
<p>You can speed up the computation by using n_jobs=-1, which will spread
the computation equally across all processors (but will probably not work
under Windows):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">fmri_masked</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> 
</pre></div>
</div>
<p><strong>Prediction accuracy</strong>: We can take a look at the results of the
<em>cross_val_score</em> function:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span> 
<span class="go">[0.72727272727272729, 0.46511627906976744, 0.72093023255813948, 0.58139534883720934, 0.7441860465116279]</span>
</pre></div>
</div>
<p>This is simply the prediction score for each fold, i.e. the fraction of
correct predictions on the left-out data.</p>
</div>
<div class="section" id="choosing-a-good-cross-validation-strategy">
<h4>2.1.2.2.2. Choosing a good cross-validation strategy<a class="headerlink" href="#choosing-a-good-cross-validation-strategy" title="Permalink to this headline">¶</a></h4>
<p>There are many cross-validation strategies possible, including K-Fold or
leave-one-out. When choosing a strategy, keep in mind that:</p>
<ul class="simple">
<li>The test set should be as litte correlated as possible with the train
set</li>
<li>The test set needs to have enough samples to enable a good measure of
the prediction error (a rule of thumb is to use 10 to 20% of the data).</li>
</ul>
<p>In these regards, leave one out is often one of the worst options.</p>
<p>Here, in the Haxby example, we are going to leave a session out, in order
to have a test set independent from the train set. For this, we are going
to use the session label, present in the behavioral data file, and
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.LeaveOneLabelOut.html#sklearn.cross_validation.LeaveOneLabelOut" title="(in scikit-learn v0.16.dev0)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.cross_validation.LeaveOneLabelOut</span></code></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">LeaveOneLabelOut</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">session_label</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="s">&#39;chunks&#39;</span><span class="p">]</span> 
<span class="gp">&gt;&gt;&gt; </span><span class="c"># We need to remember to remove the rest conditions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">session_label</span> <span class="o">=</span> <span class="n">session_label</span><span class="p">[</span><span class="n">condition_mask</span><span class="p">]</span> 
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv</span> <span class="o">=</span> <span class="n">LeaveOneLabelOut</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">session_label</span><span class="p">)</span> 
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">fmri_masked</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
<span class="go">[ 1.          0.61111111  0.94444444  0.88888889  0.88888889  0.94444444</span>
<span class="go">  0.72222222  0.94444444  0.5         0.72222222  0.5         0.55555556]</span>
</pre></div>
</div>
<div class="green topic">
<p class="topic-title first"><strong>Exercise</strong></p>
<p>Compute the mean prediction accuracy using <em>cv_scores</em></p>
</div>
<div class="topic">
<p class="topic-title first">Solution</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">classification_accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classification_accuracy</span> 
<span class="go">0.76851851851851849</span>
</pre></div>
</div>
</div>
<p>We have a total prediction accuracy of 77% across the different sessions.</p>
</div>
<div class="section" id="choice-of-the-prediction-accuracy-measure">
<h4>2.1.2.2.3. Choice of the prediction accuracy measure<a class="headerlink" href="#choice-of-the-prediction-accuracy-measure" title="Permalink to this headline">¶</a></h4>
<p>The default metric used for measuring errors is the accuracy score, i.e.
the number of total errors. It is not always a sensible metric,
especially in the case of very imbalanced classes, as in such situations
choosing the dominant class can achieve a low number of errors.</p>
<p>Other metrics, such as the f1-score, can be used:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">fmri_masked</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>  <span class="n">scoring</span><span class="o">=</span><span class="s">&#39;f1&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last">the <a class="reference external" href="http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values">list of scoring options</a></p>
</div>
</div>
<div class="section" id="measuring-the-chance-level">
<h4>2.1.2.2.4. Measuring the chance level<a class="headerlink" href="#measuring-the-chance-level" title="Permalink to this headline">¶</a></h4>
<p><strong>Dummy estimators</strong>: The simplest way to measure prediction performance
at chance, is to use a dummy classifier,
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html#sklearn.dummy.DummyClassifier" title="(in scikit-learn v0.16.dev0)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.dummy.DummyClassifier</span></code></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">null_cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">DummyClassifier</span><span class="p">(),</span> <span class="n">fmri_masked</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Permutation testing</strong>: A more controlled way, but slower, is to do
permutation testing on the labels, with
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.permutation_test_score.html#sklearn.cross_validation.permutation_test_score" title="(in scikit-learn v0.16.dev0)"><code class="xref py py-func docutils literal"><span class="pre">sklearn.cross_validation.permutation_test_score</span></code></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">permutation_test_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">null_cv_scores</span> <span class="o">=</span> <span class="n">permutation_test_score</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">fmri_masked</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="topic">
<p class="topic-title first"><strong>Putting it all together</strong></p>
<p>The <a class="reference internal" href="../auto_examples/decoding/plot_haxby_full_analysis.html#example-decoding-plot-haxby-full-analysis-py"><span>ROI-based decoding example</span></a> does a decoding analysis per
mask, giving the f1-score of the prediction for each object.</p>
<p>It uses all the notions presented above, with <code class="docutils literal"><span class="pre">for</span></code> loop to iterate
over masks and categories and Python dictionnaries to store the
scores.</p>
</div>
<div class="figure align-left" id="id5">
<a class="reference external image-reference" href="../auto_examples/manipulating_visualizing/plot_haxby_masks.html"><img alt="../_images/plot_haxby_masks_0011.png" src="../_images/plot_haxby_masks_0011.png" style="width: 220.0px; height: 297.0px;" /></a>
<p class="caption"><span class="caption-text">Masks</span></p>
</div>
<div class="figure align-left">
<a class="reference external image-reference" href="../auto_examples/decoding/plot_haxby_full_analysis.html"><img alt="../_images/plot_haxby_full_analysis_0011.png" src="../_images/plot_haxby_full_analysis_0011.png" style="width: 560.0px; height: 420.0px;" /></a>
</div>
</div>
</div>
<div class="section" id="visualizing-the-decoder-s-weights">
<h3>2.1.2.3. Visualizing the decoder&#8217;s weights<a class="headerlink" href="#visualizing-the-decoder-s-weights" title="Permalink to this headline">¶</a></h3>
<p>We can visualize the weights of the decoder:</p>
<ul class="simple">
<li>we first inverse the masking operation, to retrieve a 3D brain volume
of the SVC&#8217;s weights.</li>
<li>we then create a figure and plot as a background the first EPI image</li>
<li>finally we plot the SVC&#8217;s weights after masking the zero values</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Retrieve the SVC discriminating weights</span>
<span class="n">coef_</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">coef_</span>

<span class="c"># Reverse masking thanks to the Nifti Masker</span>
<span class="n">coef_img</span> <span class="o">=</span> <span class="n">nifti_masker</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">coef_</span><span class="p">)</span>

<span class="c"># Save the coefficients as a Nifti image</span>
<span class="n">coef_img</span><span class="o">.</span><span class="n">to_filename</span><span class="p">(</span><span class="s">&#39;haxby_svc_weights.nii&#39;</span><span class="p">)</span>

<span class="c">### Visualization #############################################################</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">nilearn.image.image</span> <span class="kn">import</span> <span class="n">mean_img</span>
<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="kn">import</span> <span class="n">plot_roi</span><span class="p">,</span> <span class="n">plot_stat_map</span>

<span class="n">mean_epi</span> <span class="o">=</span> <span class="n">mean_img</span><span class="p">(</span><span class="n">func_filename</span><span class="p">)</span>
<span class="n">plot_stat_map</span><span class="p">(</span><span class="n">coef_img</span><span class="p">,</span> <span class="n">mean_epi</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&quot;SVM weights&quot;</span><span class="p">,</span> <span class="n">display_mode</span><span class="o">=</span><span class="s">&quot;yx&quot;</span><span class="p">)</span>

<span class="n">plot_roi</span><span class="p">(</span><span class="n">nifti_masker</span><span class="o">.</span><span class="n">mask_img_</span><span class="p">,</span> <span class="n">mean_epi</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&quot;Mask&quot;</span><span class="p">,</span> <span class="n">display_mode</span><span class="o">=</span><span class="s">&quot;yx&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="figure">
<a class="reference external image-reference" href="../auto_examples/plot_haxby_simple.html"><img alt="../_images/plot_haxby_simple_0012.png" src="../_images/plot_haxby_simple_0012.png" style="width: 331.5px; height: 169.0px;" /></a>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<ul class="last simple">
<li><a class="reference internal" href="../manipulating_visualizing/plotting.html#plotting"><span>Plotting brain images</span></a></li>
</ul>
</div>
</div>
</div>
<div class="section" id="decoding-without-a-mask-anova-svm">
<h2><a class="toc-backref" href="#id8">2.1.3. Decoding without a mask: Anova-SVM</a><a class="headerlink" href="#decoding-without-a-mask-anova-svm" title="Permalink to this headline">¶</a></h2>
<div class="section" id="dimension-reduction-with-feature-selection">
<h3>2.1.3.1. Dimension reduction with feature selection<a class="headerlink" href="#dimension-reduction-with-feature-selection" title="Permalink to this headline">¶</a></h3>
<p>If we do not start from a mask of the relevant regions, there is a very
large number of voxels and not all are useful for
face vs cat prediction. We thus add a <a class="reference external" href="http://scikit-learn.org/stable/modules/feature_selection.html">feature selection</a>
procedure. The idea is to select the <cite>k</cite> voxels most correlated to the
task.</p>
<p>For this, we need to import the <a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection" title="(in scikit-learn v0.16.dev0)"><code class="xref py py-mod docutils literal"><span class="pre">sklearn.feature_selection</span></code></a> module and use
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif" title="(in scikit-learn v0.16.dev0)"><code class="xref py py-func docutils literal"><span class="pre">sklearn.feature_selection.f_classif</span></code></a>, a simple F-score
based feature selection (a.k.a.
<a class="reference external" href="http://en.wikipedia.org/wiki/Analysis_of_variance#The_F-test">Anova</a>),
that we will put before the SVC in a <cite>pipeline</cite>
(<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v0.16.dev0)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.pipeline.Pipeline</span></code></a>):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>

<span class="c">### Define the dimension reduction to be used.</span>
<span class="c"># Here we use a classical univariate feature selection based on F-test,</span>
<span class="c"># namely Anova. We set the number of features to be selected to 500</span>
<span class="n">feature_selection</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>

<span class="c"># We have our classifier (SVC), our feature selection (SelectKBest), and now,</span>
<span class="c"># we can plug them together in a *pipeline* that performs the two operations</span>
<span class="c"># successively:</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">anova_svc</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;anova&#39;</span><span class="p">,</span> <span class="n">feature_selection</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;svc&#39;</span><span class="p">,</span> <span class="n">svc</span><span class="p">)])</span>

<span class="c">### Fit and predict ###########################################################</span>

<span class="n">anova_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">anova_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p>We can use our <code class="docutils literal"><span class="pre">anova_svc</span></code> object exactly as we were using our <code class="docutils literal"><span class="pre">svc</span></code>
object previously.</p>
</div>
<div class="section" id="visualizing-the-results">
<h3>2.1.3.2. Visualizing the results<a class="headerlink" href="#visualizing-the-results" title="Permalink to this headline">¶</a></h3>
<p>To visualize the results, we need to:</p>
<ul class="simple">
<li>first get the support vectors of the SVC and inverse the feature
selection mechanism</li>
<li>then, as before, inverse the masking process to retrieve the weights
and plot them.</li>
</ul>
<div class="figure align-right">
<a class="reference external image-reference" href="../auto_examples/decoding/plot_haxby_anova_svm.html"><img alt="../_images/plot_haxby_anova_svm_0011.png" src="../_images/plot_haxby_anova_svm_0011.png" style="width: 474.5px; height: 169.0px;" /></a>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="c">### Look at the SVC&#39;s discriminating weights</span>
<span class="n">coef</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">coef_</span>
<span class="c"># reverse feature selection</span>
<span class="n">coef</span> <span class="o">=</span> <span class="n">feature_selection</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>
<span class="c"># reverse masking</span>
<span class="n">weight_img</span> <span class="o">=</span> <span class="n">nifti_masker</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>


<span class="c">### Create the figure</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="kn">import</span> <span class="n">plot_stat_map</span>

<span class="c"># Plot the mean image because we have no anatomic data</span>
<span class="n">mean_img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">mean_img</span><span class="p">(</span><span class="n">func_filename</span><span class="p">)</span>

<span class="n">plot_stat_map</span><span class="p">(</span><span class="n">weight_img</span><span class="p">,</span> <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;SVM weights&#39;</span><span class="p">)</span>

<span class="c">### Saving the results as a Nifti file may also be important</span>
<span class="n">weight_img</span><span class="o">.</span><span class="n">to_filename</span><span class="p">(</span><span class="s">&#39;haxby_face_vs_house.nii&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<ul class="last simple">
<li><a class="reference internal" href="../manipulating_visualizing/plotting.html#plotting"><span>Plotting brain images</span></a></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first"><strong>Final script</strong></p>
<p>The complete script to do an SVM-Anova analysis can be found as
<a class="reference internal" href="../auto_examples/decoding/plot_haxby_anova_svm.html#example-decoding-plot-haxby-anova-svm-py"><span>an example</span></a>.</p>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<ul class="last simple">
<li><a class="reference internal" href="searchlight.html#searchlight"><span>Searchlight : finding voxels containing information</span></a></li>
<li><a class="reference internal" href="decoding_simulated.html#decoding-simulated"><span>Decoding on simulated data</span></a></li>
</ul>
</div>
</div>
</div>
<div class="section" id="going-further-with-scikit-learn">
<h2><a class="toc-backref" href="#id9">2.1.4. Going further with scikit-learn</a><a class="headerlink" href="#going-further-with-scikit-learn" title="Permalink to this headline">¶</a></h2>
<p>We have seen a very simple analysis with scikit-learn, but it may be
interesting to explore the <a class="reference external" href="http://scikit-learn.org/stable/supervised_learning.html">wide variety of supervised learning
algorithms in the scikit-learn</a>.</p>
<div class="section" id="changing-the-prediction-engine">
<h3>2.1.4.1. Changing the prediction engine<a class="headerlink" href="#changing-the-prediction-engine" title="Permalink to this headline">¶</a></h3>
<p>We now see how one can easily change the prediction engine, if needed.
We can try Fisher&#8217;s <a class="reference external" href="http://scikit-learn.org/auto_examples/plot_lda_qda.html">Linear Discriminant Analysis (LDA)</a></p>
<p>Import the module:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.lda</span> <span class="kn">import</span> <span class="n">LDA</span>
</pre></div>
</div>
<p>Construct the new estimator object and use it in a pipeline:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anova_lda</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;anova&#39;</span><span class="p">,</span> <span class="n">feature_selection</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;LDA&#39;</span><span class="p">,</span> <span class="n">lda</span><span class="p">)])</span>
</pre></div>
</div>
<p>and recompute the cross-validation score:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">anova_lda</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classification_accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_scores</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="s">&quot;Classification accuracy: </span><span class="si">%.4f</span><span class="s"> / Chance Level: </span><span class="si">%.4f</span><span class="s">&quot;</span> <span class="o">%</span> \
<span class="gp">... </span>   <span class="p">(</span><span class="n">classification_accuracy</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">n_conditions</span><span class="p">))</span> 
<span class="go">Classification accuracy: 1.0000 / Chance level: 0.5000</span>
</pre></div>
</div>
</div>
<div class="section" id="changing-the-feature-selection">
<h3>2.1.4.2. Changing the feature selection<a class="headerlink" href="#changing-the-feature-selection" title="Permalink to this headline">¶</a></h3>
<p>Let&#8217;s say that you want a more sophisticated feature selection, for example a
<a class="reference external" href="http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination">Recursive Feature Elimination (RFE)</a></p>
<p>Import the module:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
</pre></div>
</div>
<p>Construct your new fancy selection:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.</span><span class="p">),</span> <span class="mi">50</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
</pre></div>
</div>
<p>and create a new pipeline:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">rfe_svc</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;rfe&#39;</span><span class="p">,</span> <span class="n">rfe</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;svc&#39;</span><span class="p">,</span> <span class="n">clf</span><span class="p">)])</span>
</pre></div>
</div>
<p>and recompute the cross-validation score:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rfe_svc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
</pre></div>
</div>
<p>But, be aware that this can take A WHILE...</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<ul class="last simple">
<li>The <a class="reference external" href="http://scikit-learn.org">scikit-learn documentation</a>
has very detailed explanations on a large variety of estimators and
machine learning techniques. To become better at decoding, you need
to study it.</li>
</ul>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../np-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="estimator_choice.html" title="2.2. Choosing the right predictive model"
             >next</a> |</li>
        <li class="right" >
          <a href="index.html" title="2. Decoding and MVPA: predicting from brain images"
             >previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="index.html" >2. Decoding and MVPA: predicting from brain images</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
            &copy; The nilearn developers 2010-2015.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.1.
        <span style="padding-left: 5ex;">
          <a href="../_sources/decoding/decoding_tutorial.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>